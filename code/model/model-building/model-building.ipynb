{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1971,
     "status": "ok",
     "timestamp": 1583786158091,
     "user": {
      "displayName": "Jacob Ellena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GipDwLM6i3xdI-QK1rxlUihbf6PtSR2caa4RHyCvKA=s64",
      "userId": "05902103246554275059"
     },
     "user_tz": 240
    },
    "id": "DFqHhMm-ALnn",
    "outputId": "591ecb7b-8218-45fd-f547-6a354ccf30a6"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the sequence length\n",
    "seq_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2633,
     "status": "error",
     "timestamp": 1583786167577,
     "user": {
      "displayName": "Jacob Ellena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GipDwLM6i3xdI-QK1rxlUihbf6PtSR2caa4RHyCvKA=s64",
      "userId": "05902103246554275059"
     },
     "user_tz": 240
    },
    "id": "15lZkzAJALns",
    "outputId": "86544020-22b8-473c-ce5c-4d48a4305c5d"
   },
   "outputs": [],
   "source": [
    "# Loading in Shanties lyrics corpus\n",
    "shanties = open('../../../data/shanties_all.txt', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qDPD3_cSALnv"
   },
   "source": [
    "### Converting Characters to Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rEiTIa6ALny"
   },
   "outputs": [],
   "source": [
    "# Creating a list of all unique characters\n",
    "chars_list = sorted(list(set(shanties)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-tUbc-2WALn1"
   },
   "outputs": [],
   "source": [
    "# Creating a dictionary to map each unique character to a number\n",
    "chars_to_ints = dict((c, i) for i, c in enumerate(chars_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYaoX1N8ALn3",
    "outputId": "a1326695-698e-4c44-b284-99c13663ebd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of corpus  :  696418\n",
      "Total unique characters :  27\n"
     ]
    }
   ],
   "source": [
    "# Checking length of corpus and unique characters\n",
    "len_shanties = len(shanties)\n",
    "n_chars = len(chars_list)\n",
    "\n",
    "print(f'Total length of corpus  :  {len_shanties}')\n",
    "print(f'Total unique characters :  {n_chars}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "juRTFNlQALn7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of 50 character lenght patters: 696368\n"
     ]
    }
   ],
   "source": [
    "# Creating a list of patterns for the entire corpus\n",
    "\n",
    "X_data = []\n",
    "y_data = []\n",
    "for i in range(0, len_shanties - seq_len, 1):\n",
    "    seq_in = shanties[i:i + seq_len]\n",
    "    seq_out = shanties[i + seq_len]\n",
    "    X_data.append([chars_to_ints[char] for char in seq_in])\n",
    "    y_data.append(chars_to_ints[seq_out])\n",
    "\n",
    "total_patterns = len(X_data)\n",
    "print(f'Total number of {seq_len} character lenght patters: {total_patterns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Axp96CLQALn-"
   },
   "outputs": [],
   "source": [
    "# Reshaping Data for use in LSTM networks\n",
    "X = np.reshape(X_data, (total_patterns, seq_len, 1))\n",
    "\n",
    "# Normalzing X data\n",
    "X = X / float(n_chars)\n",
    "\n",
    "# One hot encode to the output variable\n",
    "y = np_utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a checkpoint to find best weights\n",
    "checkpoint_name = './model-weights/' + str(seq_len) + '-char-sequence/' + str(seq_len) + '-char-seq-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model-weights/50-char-sequence/50-char-seq-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'./model-weights/' + str(seq_len) + '-char-sequence/' + str(seq_len) + '-char-seq-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and Running Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vck9_39tALoA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 21:01:09.672340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 21:01:09.716864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 21:01:09.716998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 21:01:09.717956: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-14 21:01:09.718680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 21:01:09.718809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 21:01:09.718907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 21:01:10.228046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 21:01:10.228208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 21:01:10.228315: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 21:01:10.228410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9236 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Defining LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# Adding layers\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "# Compiling model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 21:01:19.696880: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8300\n",
      "2021-11-14 21:01:19.831825: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5441/5441 [==============================] - ETA: 0s - loss: 2.3377\n",
      "Epoch 00001: loss improved from inf to 2.33771, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-01-2.3377.hdf5\n",
      "5441/5441 [==============================] - 63s 11ms/step - loss: 2.3377\n",
      "Epoch 2/20\n",
      "5440/5441 [============================>.] - ETA: 0s - loss: 1.9722\n",
      "Epoch 00002: loss improved from 2.33771 to 1.97222, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-02-1.9722.hdf5\n",
      "5441/5441 [==============================] - 61s 11ms/step - loss: 1.9722\n",
      "Epoch 3/20\n",
      "5441/5441 [==============================] - ETA: 0s - loss: 1.8376\n",
      "Epoch 00003: loss improved from 1.97222 to 1.83760, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-03-1.8376.hdf5\n",
      "5441/5441 [==============================] - 60s 11ms/step - loss: 1.8376\n",
      "Epoch 4/20\n",
      "5441/5441 [==============================] - ETA: 0s - loss: 1.7559\n",
      "Epoch 00004: loss improved from 1.83760 to 1.75588, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-04-1.7559.hdf5\n",
      "5441/5441 [==============================] - 60s 11ms/step - loss: 1.7559\n",
      "Epoch 5/20\n",
      "5441/5441 [==============================] - ETA: 0s - loss: 1.6948\n",
      "Epoch 00005: loss improved from 1.75588 to 1.69483, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-05-1.6948.hdf5\n",
      "5441/5441 [==============================] - 61s 11ms/step - loss: 1.6948\n",
      "Epoch 6/20\n",
      "5441/5441 [==============================] - ETA: 0s - loss: 1.6505\n",
      "Epoch 00006: loss improved from 1.69483 to 1.65052, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-06-1.6505.hdf5\n",
      "5441/5441 [==============================] - 61s 11ms/step - loss: 1.6505\n",
      "Epoch 7/20\n",
      "5437/5441 [============================>.] - ETA: 0s - loss: 1.6151\n",
      "Epoch 00007: loss improved from 1.65052 to 1.61505, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-07-1.6150.hdf5\n",
      "5441/5441 [==============================] - 60s 11ms/step - loss: 1.6150\n",
      "Epoch 8/20\n",
      "5441/5441 [==============================] - ETA: 0s - loss: 1.5857\n",
      "Epoch 00008: loss improved from 1.61505 to 1.58569, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-08-1.5857.hdf5\n",
      "5441/5441 [==============================] - 61s 11ms/step - loss: 1.5857\n",
      "Epoch 9/20\n",
      "5441/5441 [==============================] - ETA: 0s - loss: 1.5617\n",
      "Epoch 00009: loss improved from 1.58569 to 1.56167, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-09-1.5617.hdf5\n",
      "5441/5441 [==============================] - 61s 11ms/step - loss: 1.5617\n",
      "Epoch 10/20\n",
      "5439/5441 [============================>.] - ETA: 0s - loss: 1.5419\n",
      "Epoch 00010: loss improved from 1.56167 to 1.54198, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-10-1.5420.hdf5\n",
      "5441/5441 [==============================] - 61s 11ms/step - loss: 1.5420\n",
      "Epoch 11/20\n",
      "5441/5441 [==============================] - ETA: 0s - loss: 1.5230\n",
      "Epoch 00011: loss improved from 1.54198 to 1.52302, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-11-1.5230.hdf5\n",
      "5441/5441 [==============================] - 61s 11ms/step - loss: 1.5230\n",
      "Epoch 12/20\n",
      "5439/5441 [============================>.] - ETA: 0s - loss: 1.5083\n",
      "Epoch 00012: loss improved from 1.52302 to 1.50845, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-12-1.5084.hdf5\n",
      "5441/5441 [==============================] - 61s 11ms/step - loss: 1.5084\n",
      "Epoch 13/20\n",
      "5441/5441 [==============================] - ETA: 0s - loss: 1.4951\n",
      "Epoch 00013: loss improved from 1.50845 to 1.49509, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-13-1.4951.hdf5\n",
      "5441/5441 [==============================] - 60s 11ms/step - loss: 1.4951\n",
      "Epoch 14/20\n",
      "5440/5441 [============================>.] - ETA: 0s - loss: 1.4852\n",
      "Epoch 00014: loss improved from 1.49509 to 1.48522, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-14-1.4852.hdf5\n",
      "5441/5441 [==============================] - 61s 11ms/step - loss: 1.4852\n",
      "Epoch 15/20\n",
      "5436/5441 [============================>.] - ETA: 0s - loss: 1.4742\n",
      "Epoch 00015: loss improved from 1.48522 to 1.47427, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-15-1.4743.hdf5\n",
      "5441/5441 [==============================] - 61s 11ms/step - loss: 1.4743\n",
      "Epoch 16/20\n",
      "5441/5441 [==============================] - ETA: 0s - loss: 1.4650\n",
      "Epoch 00016: loss improved from 1.47427 to 1.46498, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-16-1.4650.hdf5\n",
      "5441/5441 [==============================] - 60s 11ms/step - loss: 1.4650\n",
      "Epoch 17/20\n",
      "5441/5441 [==============================] - ETA: 0s - loss: 1.4575\n",
      "Epoch 00017: loss improved from 1.46498 to 1.45746, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-17-1.4575.hdf5\n",
      "5441/5441 [==============================] - 61s 11ms/step - loss: 1.4575\n",
      "Epoch 18/20\n",
      "5440/5441 [============================>.] - ETA: 0s - loss: 1.4515\n",
      "Epoch 00018: loss improved from 1.45746 to 1.45146, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-18-1.4515.hdf5\n",
      "5441/5441 [==============================] - 61s 11ms/step - loss: 1.4515\n",
      "Epoch 19/20\n",
      "5438/5441 [============================>.] - ETA: 0s - loss: 1.4449\n",
      "Epoch 00019: loss improved from 1.45146 to 1.44493, saving model to ./model-weights/50-char-sequence/50-char-seq-weights-improvement-19-1.4449.hdf5\n",
      "5441/5441 [==============================] - 60s 11ms/step - loss: 1.4449\n",
      "Epoch 20/20\n",
      " 916/5441 [====>.........................] - ETA: 50s - loss: 1.4262"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Model\n",
    "model.save(f'./models/{seq_len}-char-seq-shanty_writer.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "mode-test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:dsi-111]",
   "language": "python",
   "name": "conda-env-dsi-111-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
